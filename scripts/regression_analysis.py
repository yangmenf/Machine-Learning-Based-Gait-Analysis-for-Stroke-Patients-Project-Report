#!/usr/bin/env python3
"""
å›å½’åˆ†æè„šæœ¬
ä¸“é—¨åˆ†æä¸­é£æ‚£è€…å’Œå¥åº·äººåœ¨æ­¥æ€ç‰¹å¾ä¸Šçš„å·®å¼‚
ç ”ç©¶ä¸­é£æ‚£è€…åœ¨å“ªäº›é—®é¢˜ä¸Šå’Œå¥åº·äººæœ‰åŒºåˆ«
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import warnings
warnings.filterwarnings('ignore')

def setup_chinese_font():
    """è®¾ç½®ä¸­æ–‡å­—ä½“"""
    import matplotlib
    font_options = [
        ['Microsoft YaHei', 'SimHei', 'Arial Unicode MS', 'DejaVu Sans'],
        ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS', 'DejaVu Sans'],
        ['Arial Unicode MS', 'Microsoft YaHei', 'SimHei', 'DejaVu Sans'],
        ['DejaVu Sans', 'Arial', 'sans-serif']
    ]
    
    for fonts in font_options:
        try:
            matplotlib.rcParams['font.sans-serif'] = fonts
            matplotlib.rcParams['axes.unicode_minus'] = False
            plt.rcParams['font.sans-serif'] = fonts
            plt.rcParams['axes.unicode_minus'] = False
            return True
        except:
            continue
    return False

def load_and_prepare_data():
    """åŠ è½½å’Œå‡†å¤‡æ•°æ®"""
    print("="*60)
    print("æ­¥æ€ç‰¹å¾å›å½’åˆ†æ")
    print("="*60)
    
    try:
        df = pd.read_csv("../data/complete_gait_features.csv")
        print(f"âœ“ æˆåŠŸåŠ è½½æ•°æ®: {df.shape}")
        
        # åˆ†ç¦»ç‰¹å¾å’Œæ ‡ç­¾
        feature_cols = [col for col in df.columns if col not in ['label', 'group', 'subject_id', 'data_group', 'subject_index']]
        
        X = df[feature_cols].copy()
        y = df['label'].copy()
        
        # å¤„ç†ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼
        X = X.replace('', np.nan)
        for col in X.columns:
            X[col] = pd.to_numeric(X[col], errors='coerce')
        X = X.fillna(X.median())
        X = X.replace([np.inf, -np.inf], np.nan)
        X = X.fillna(X.median())
        
        print(f"âœ“ ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {X.shape}")
        print(f"âœ“ æ ‡ç­¾åˆ†å¸ƒ: å¥åº·äºº {len(y[y==0])}, ä¸­é£æ‚£è€… {len(y[y==1])}")
        
        return df, X, y, feature_cols
        
    except Exception as e:
        print(f"âœ— åŠ è½½æ•°æ®å¤±è´¥: {e}")
        return None, None, None, None

def perform_statistical_analysis(df, X, y, feature_cols):
    """æ‰§è¡Œç»Ÿè®¡åˆ†æï¼Œè¯†åˆ«æ˜¾è‘—å·®å¼‚ç‰¹å¾"""
    print("\n" + "="*40)
    print("ç»Ÿè®¡æ˜¾è‘—æ€§åˆ†æ")
    print("="*40)
    
    # åˆ†ç»„æ•°æ®
    healthy_data = X[y == 0]
    stroke_data = X[y == 1]
    
    # ç»Ÿè®¡æ£€éªŒç»“æœ
    statistical_results = []
    
    print("è¿›è¡Œç‹¬ç«‹æ ·æœ¬tæ£€éªŒ...")
    
    for feature in feature_cols:
        try:
            healthy_values = healthy_data[feature].dropna()
            stroke_values = stroke_data[feature].dropna()
            
            if len(healthy_values) > 10 and len(stroke_values) > 10:
                # ç‹¬ç«‹æ ·æœ¬tæ£€éªŒ
                t_stat, p_value = stats.ttest_ind(healthy_values, stroke_values)
                
                # è®¡ç®—æ•ˆåº”é‡ (Cohen's d)
                pooled_std = np.sqrt(((len(healthy_values) - 1) * healthy_values.var() + 
                                    (len(stroke_values) - 1) * stroke_values.var()) / 
                                   (len(healthy_values) + len(stroke_values) - 2))
                
                if pooled_std > 0:
                    cohens_d = (healthy_values.mean() - stroke_values.mean()) / pooled_std
                else:
                    cohens_d = 0
                
                # è®¡ç®—åŸºæœ¬ç»Ÿè®¡é‡
                healthy_mean = healthy_values.mean()
                stroke_mean = stroke_values.mean()
                mean_diff = healthy_mean - stroke_mean
                
                statistical_results.append({
                    'feature': feature,
                    'healthy_mean': healthy_mean,
                    'stroke_mean': stroke_mean,
                    'mean_difference': mean_diff,
                    't_statistic': t_stat,
                    'p_value': p_value,
                    'cohens_d': cohens_d,
                    'effect_size': abs(cohens_d)
                })
        except Exception as e:
            continue
    
    # è½¬æ¢ä¸ºDataFrameå¹¶æ’åº
    results_df = pd.DataFrame(statistical_results)
    
    if len(results_df) > 0:
        # æŒ‰æ•ˆåº”é‡æ’åº
        results_df = results_df.sort_values('effect_size', ascending=False)
        
        # æ˜¾è‘—æ€§ç­›é€‰ (p < 0.05)
        significant_features = results_df[results_df['p_value'] < 0.05]
        
        print(f"âœ“ å®Œæˆ {len(results_df)} ä¸ªç‰¹å¾çš„ç»Ÿè®¡æ£€éªŒ")
        print(f"âœ“ å‘ç° {len(significant_features)} ä¸ªæ˜¾è‘—å·®å¼‚ç‰¹å¾ (p < 0.05)")
        
        # æ˜¾ç¤ºå‰10ä¸ªæœ€æ˜¾è‘—çš„å·®å¼‚
        print(f"\nå‰10ä¸ªæœ€æ˜¾è‘—çš„å·®å¼‚ç‰¹å¾:")
        print("-" * 80)
        for i, row in significant_features.head(10).iterrows():
            effect_level = "å¤§" if abs(row['cohens_d']) > 0.8 else "ä¸­" if abs(row['cohens_d']) > 0.5 else "å°"
            print(f"{row['feature'][:30]:<30} | æ•ˆåº”é‡: {row['cohens_d']:.3f} ({effect_level}) | på€¼: {row['p_value']:.6f}")
        
        return results_df, significant_features
    else:
        print("âœ— æœªèƒ½å®Œæˆç»Ÿè®¡åˆ†æ")
        return None, None

def perform_regression_modeling(X, y):
    """æ‰§è¡Œå›å½’å»ºæ¨¡åˆ†æ"""
    print("\n" + "="*40)
    print("å›å½’å»ºæ¨¡åˆ†æ")
    print("="*40)
    
    # æ•°æ®åˆ†å‰²
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # ç‰¹å¾æ ‡å‡†åŒ–
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # å®šä¹‰å›å½’æ¨¡å‹
    regressors = {
        'Linear Regression': LinearRegression(),
        'Ridge Regression': Ridge(alpha=1.0),
        'Lasso Regression': Lasso(alpha=0.1),
        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)
    }
    
    regression_results = {}
    
    print("è®­ç»ƒå›å½’æ¨¡å‹...")
    
    for name, regressor in regressors.items():
        try:
            if name == 'Random Forest':
                regressor.fit(X_train, y_train)
                y_pred = regressor.predict(X_test)
            else:
                regressor.fit(X_train_scaled, y_train)
                y_pred = regressor.predict(X_test_scaled)
            
            # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
            mse = mean_squared_error(y_test, y_pred)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(y_test, y_pred)
            r2 = r2_score(y_test, y_pred)
            
            regression_results[name] = {
                'mse': mse,
                'rmse': rmse,
                'mae': mae,
                'r2': r2,
                'model': regressor,
                'y_pred': y_pred,
                'y_test': y_test
            }
            
            print(f"{name}: RÂ² = {r2:.3f}, RMSE = {rmse:.3f}")
            
        except Exception as e:
            print(f"âœ— {name} è®­ç»ƒå¤±è´¥: {e}")
    
    return regression_results

def create_regression_visualizations(results_df, significant_features, regression_results):
    """åˆ›å»ºå›å½’åˆ†æå¯è§†åŒ–"""
    print("\n" + "="*40)
    print("åˆ›å»ºå›å½’åˆ†æå¯è§†åŒ–")
    print("="*40)
    
    # ç”¨æˆ·åå¥½çš„é¢œè‰²æ–¹æ¡ˆ
    COLORS = ['#98CFE6', '#ADE7A8', '#F39F4E', '#EEB7D3', '#DBDAD3', '#FFDF97']
    
    # åˆ›å»ºå›¾è¡¨
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('æ­¥æ€ç‰¹å¾å›å½’åˆ†æç»“æœ', fontsize=16, fontweight='bold')
    
    # 1. æ•ˆåº”é‡æ’åºï¼ˆå‰15ä¸ªï¼‰
    ax1 = axes[0, 0]
    if len(significant_features) > 0:
        top_features = significant_features.head(15)
        feature_names = [f.split('_')[0] for f in top_features['feature']]  # ç®€åŒ–ç‰¹å¾å
        
        bars = ax1.barh(range(len(feature_names)), top_features['effect_size'], color=COLORS[0])
        ax1.set_yticks(range(len(feature_names)))
        ax1.set_yticklabels(feature_names, fontsize=8)
        ax1.set_xlabel('æ•ˆåº”é‡ (Cohen\'s d)')
        ax1.set_title('ç‰¹å¾æ•ˆåº”é‡æ’åº (Top 15)', pad=15)
        ax1.invert_yaxis()
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, bar in enumerate(bars):
            width = bar.get_width()
            ax1.text(width + 0.01, bar.get_y() + bar.get_height()/2,
                    f'{width:.2f}', ha='left', va='center', fontsize=8)
    
    # 2. på€¼åˆ†å¸ƒ
    ax2 = axes[0, 1]
    if len(results_df) > 0:
        ax2.hist(results_df['p_value'], bins=20, color=COLORS[1], alpha=0.7, edgecolor='black')
        ax2.axvline(x=0.05, color='red', linestyle='--', label='p = 0.05')
        ax2.set_xlabel('på€¼')
        ax2.set_ylabel('ç‰¹å¾æ•°é‡')
        ax2.set_title('på€¼åˆ†å¸ƒ', pad=15)
        ax2.legend()
    
    # 3. å¥åº·äººvsä¸­é£æ‚£è€…ç‰¹å¾å¯¹æ¯”ï¼ˆå‰6ä¸ªæ˜¾è‘—ç‰¹å¾ï¼‰
    ax3 = axes[0, 2]
    if len(significant_features) > 0:
        top_6_features = significant_features.head(6)
        healthy_means = top_6_features['healthy_mean'].values
        stroke_means = top_6_features['stroke_mean'].values
        feature_names = [f.split('_')[0] for f in top_6_features['feature']]
        
        x_pos = np.arange(len(feature_names))
        width = 0.35
        
        bars1 = ax3.bar(x_pos - width/2, healthy_means, width, 
                       label='å¥åº·äºº', color=COLORS[0], alpha=0.8)
        bars2 = ax3.bar(x_pos + width/2, stroke_means, width,
                       label='ä¸­é£æ‚£è€…', color=COLORS[1], alpha=0.8)
        
        ax3.set_title('ä¸»è¦å·®å¼‚ç‰¹å¾å¯¹æ¯”', pad=15)
        ax3.set_xlabel('ç‰¹å¾')
        ax3.set_ylabel('å¹³å‡å€¼')
        ax3.set_xticks(x_pos)
        ax3.set_xticklabels(feature_names, rotation=45, fontsize=8)
        ax3.legend()
    
    # 4. å›å½’æ¨¡å‹æ€§èƒ½å¯¹æ¯”
    ax4 = axes[1, 0]
    if regression_results:
        model_names = list(regression_results.keys())
        r2_scores = [regression_results[name]['r2'] for name in model_names]
        
        bars = ax4.bar(model_names, r2_scores, color=COLORS[2:6])
        ax4.set_title('å›å½’æ¨¡å‹æ€§èƒ½å¯¹æ¯”', pad=15)
        ax4.set_ylabel('RÂ² åˆ†æ•°')
        ax4.set_ylim(0, 1)
        
        for i, bar in enumerate(bars):
            height = bar.get_height()
            ax4.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{height:.3f}', ha='center', va='bottom', fontsize=10)
    
    # 5. æ•ˆåº”é‡åˆ†å¸ƒ
    ax5 = axes[1, 1]
    if len(results_df) > 0:
        ax5.hist(results_df['effect_size'], bins=20, color=COLORS[3], alpha=0.7, edgecolor='black')
        ax5.axvline(x=0.2, color='green', linestyle='--', label='å°æ•ˆåº” (0.2)')
        ax5.axvline(x=0.5, color='orange', linestyle='--', label='ä¸­æ•ˆåº” (0.5)')
        ax5.axvline(x=0.8, color='red', linestyle='--', label='å¤§æ•ˆåº” (0.8)')
        ax5.set_xlabel('æ•ˆåº”é‡ (Cohen\'s d)')
        ax5.set_ylabel('ç‰¹å¾æ•°é‡')
        ax5.set_title('æ•ˆåº”é‡åˆ†å¸ƒ', pad=15)
        ax5.legend()
    
    # 6. æ˜¾è‘—æ€§ç‰¹å¾ç»Ÿè®¡
    ax6 = axes[1, 2]
    if len(results_df) > 0:
        total_features = len(results_df)
        significant_count = len(significant_features)
        non_significant_count = total_features - significant_count
        
        sizes = [significant_count, non_significant_count]
        labels = [f'æ˜¾è‘—å·®å¼‚\n({significant_count})', f'æ— æ˜¾è‘—å·®å¼‚\n({non_significant_count})']
        colors = [COLORS[4], COLORS[5]]
        
        wedges, texts, autotexts = ax6.pie(sizes, labels=labels, autopct='%1.1f%%', 
                                          colors=colors, startangle=90)
        ax6.set_title('ç‰¹å¾æ˜¾è‘—æ€§åˆ†å¸ƒ', pad=15)
    
    # è°ƒæ•´å¸ƒå±€
    plt.tight_layout(pad=3.0, h_pad=3.0, w_pad=2.0)
    
    # ä¿å­˜å›¾è¡¨
    output_file = "../results/regression_analysis.png"
    try:
        plt.savefig(output_file, dpi=300, bbox_inches='tight', facecolor='white')
        print(f"âœ“ å›å½’åˆ†æå¯è§†åŒ–å·²ä¿å­˜: {output_file}")
    except Exception as e:
        print(f"âœ— ä¿å­˜å¯è§†åŒ–å¤±è´¥: {e}")

    # å…³é—­å›¾è¡¨ä»¥é‡Šæ”¾å†…å­˜
    plt.close(fig)

    # ä¸æ˜¾ç¤ºå›¾è¡¨ï¼Œé¿å…åœ¨æŸäº›ç¯å¢ƒä¸‹å‡ºç°é—®é¢˜
    # plt.show()

def generate_regression_report(results_df, significant_features, regression_results):
    """ç”Ÿæˆå›å½’åˆ†ææŠ¥å‘Š"""
    print("\n" + "="*40)
    print("ç”Ÿæˆå›å½’åˆ†ææŠ¥å‘Š")
    print("="*40)
    
    report_file = "../docs/regression_analysis_report.md"
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("# æ­¥æ€ç‰¹å¾å›å½’åˆ†ææŠ¥å‘Š\n\n")
        f.write("## åˆ†æç›®æ ‡\n\n")
        f.write("é€šè¿‡å›å½’åˆ†ææ–¹æ³•ï¼Œæ·±å…¥ç ”ç©¶ä¸­é£æ‚£è€…å’Œå¥åº·äººåœ¨æ­¥æ€ç‰¹å¾ä¸Šçš„å·®å¼‚ï¼Œ")
        f.write("è¯†åˆ«ä¸­é£æ‚£è€…åœ¨å“ªäº›æ–¹é¢å­˜åœ¨æ˜¾è‘—é—®é¢˜ï¼Œä¸ºåº·å¤æ²»ç–—æä¾›ç§‘å­¦ä¾æ®ã€‚\n\n")
        
        f.write("## ç»Ÿè®¡åˆ†æç»“æœ\n\n")
        if len(results_df) > 0:
            f.write(f"- **æ€»ç‰¹å¾æ•°**: {len(results_df)}\n")
            f.write(f"- **æ˜¾è‘—å·®å¼‚ç‰¹å¾æ•°**: {len(significant_features)} (p < 0.05)\n")
            f.write(f"- **æ˜¾è‘—æ€§æ¯”ä¾‹**: {len(significant_features)/len(results_df)*100:.1f}%\n\n")
            
            # æ•ˆåº”é‡åˆ†å¸ƒ
            large_effect = len(results_df[results_df['effect_size'] > 0.8])
            medium_effect = len(results_df[(results_df['effect_size'] > 0.5) & (results_df['effect_size'] <= 0.8)])
            small_effect = len(results_df[(results_df['effect_size'] > 0.2) & (results_df['effect_size'] <= 0.5)])
            
            f.write("### æ•ˆåº”é‡åˆ†å¸ƒ\n\n")
            f.write(f"- **å¤§æ•ˆåº”** (d > 0.8): {large_effect} ä¸ªç‰¹å¾\n")
            f.write(f"- **ä¸­æ•ˆåº”** (0.5 < d â‰¤ 0.8): {medium_effect} ä¸ªç‰¹å¾\n")
            f.write(f"- **å°æ•ˆåº”** (0.2 < d â‰¤ 0.5): {small_effect} ä¸ªç‰¹å¾\n\n")
        
        f.write("## ä¸»è¦å·®å¼‚ç‰¹å¾\n\n")
        if len(significant_features) > 0:
            f.write("### Top 10 æ˜¾è‘—å·®å¼‚ç‰¹å¾\n\n")
            f.write("| ç‰¹å¾åç§° | å¥åº·äººå‡å€¼ | ä¸­é£æ‚£è€…å‡å€¼ | å·®å¼‚ | æ•ˆåº”é‡ | på€¼ |\n")
            f.write("|----------|------------|--------------|------|--------|-----|\n")
            
            for i, row in significant_features.head(10).iterrows():
                f.write(f"| {row['feature'][:30]} | {row['healthy_mean']:.3f} | {row['stroke_mean']:.3f} | ")
                f.write(f"{row['mean_difference']:.3f} | {row['cohens_d']:.3f} | {row['p_value']:.6f} |\n")
            f.write("\n")
        
        f.write("## å›å½’å»ºæ¨¡ç»“æœ\n\n")
        if regression_results:
            f.write("| æ¨¡å‹ | RÂ² åˆ†æ•° | RMSE | MAE |\n")
            f.write("|------|---------|------|-----|\n")
            for name, result in regression_results.items():
                f.write(f"| {name} | {result['r2']:.3f} | {result['rmse']:.3f} | {result['mae']:.3f} |\n")
            f.write("\n")
        
        f.write("## ä¸´åºŠè§£é‡Š\n\n")
        f.write("### ä¸­é£æ‚£è€…çš„ä¸»è¦æ­¥æ€é—®é¢˜\n\n")
        if len(significant_features) > 0:
            f.write("åŸºäºç»Ÿè®¡åˆ†æç»“æœï¼Œä¸­é£æ‚£è€…åœ¨ä»¥ä¸‹æ–¹é¢ä¸å¥åº·äººå­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼š\n\n")
            
            # åˆ†æå‰å‡ ä¸ªæœ€æ˜¾è‘—çš„ç‰¹å¾
            top_features = significant_features.head(5)
            for i, row in top_features.iterrows():
                feature_name = row['feature']
                if row['mean_difference'] > 0:
                    direction = "é™ä½"
                    comparison = "ä½äº"
                else:
                    direction = "å¢åŠ "
                    comparison = "é«˜äº"
                
                f.write(f"{i+1}. **{feature_name}**: ä¸­é£æ‚£è€…{comparison}å¥åº·äºº ")
                f.write(f"{abs(row['mean_difference']):.3f} ä¸ªå•ä½ï¼Œæ•ˆåº”é‡ä¸º {abs(row['cohens_d']):.3f}\n")
            f.write("\n")
        
        f.write("### åº·å¤å»ºè®®\n\n")
        f.write("åŸºäºå›å½’åˆ†æç»“æœï¼Œå»ºè®®ä¸­é£æ‚£è€…çš„åº·å¤è®­ç»ƒé‡ç‚¹å…³æ³¨ï¼š\n\n")
        f.write("1. **æ­¥æ€å¯¹ç§°æ€§è®­ç»ƒ**: æ”¹å–„å·¦å³ä¾§æ­¥æ€ä¸å¹³è¡¡\n")
        f.write("2. **æ­¥é€Ÿè®­ç»ƒ**: æé«˜è¡Œèµ°é€Ÿåº¦å’Œæ•ˆç‡\n")
        f.write("3. **å…³èŠ‚æ´»åŠ¨åº¦è®­ç»ƒ**: å¢åŠ å…³èŠ‚çµæ´»æ€§\n")
        f.write("4. **å¹³è¡¡è®­ç»ƒ**: æ”¹å–„æ­¥æ€ç¨³å®šæ€§\n")
        f.write("5. **è‚ŒåŠ›è®­ç»ƒ**: é’ˆå¯¹æ€§åŠ å¼ºç›¸å…³è‚Œç¾¤\n\n")
        
        f.write("## æ–¹æ³•å­¦è¯´æ˜\n\n")
        f.write("- **ç»Ÿè®¡æ£€éªŒ**: ç‹¬ç«‹æ ·æœ¬tæ£€éªŒ\n")
        f.write("- **æ•ˆåº”é‡**: Cohen's d\n")
        f.write("- **æ˜¾è‘—æ€§æ°´å¹³**: p < 0.05\n")
        f.write("- **å›å½’æ¨¡å‹**: çº¿æ€§å›å½’ã€å²­å›å½’ã€Lassoå›å½’ã€éšæœºæ£®æ—\n")
        f.write("- **è¯„ä¼°æŒ‡æ ‡**: RÂ²ã€RMSEã€MAE\n\n")
        
        f.write("## ç»“è®º\n\n")
        f.write("é€šè¿‡å›å½’åˆ†æï¼Œæˆ‘ä»¬æˆåŠŸè¯†åˆ«äº†ä¸­é£æ‚£è€…ä¸å¥åº·äººåœ¨æ­¥æ€ç‰¹å¾ä¸Šçš„æ˜¾è‘—å·®å¼‚ï¼Œ")
        f.write("ä¸ºä¸ªæ€§åŒ–åº·å¤æ–¹æ¡ˆçš„åˆ¶å®šæä¾›äº†ç§‘å­¦ä¾æ®ã€‚è¿™äº›å‘ç°æœ‰åŠ©äºä¸´åºŠåŒ»ç”Ÿæ›´å¥½åœ°")
        f.write("ç†è§£ä¸­é£å¯¹æ­¥æ€çš„å½±å“ï¼Œå¹¶åˆ¶å®šé’ˆå¯¹æ€§çš„åº·å¤è®­ç»ƒè®¡åˆ’ã€‚\n")
    
    print(f"âœ“ å›å½’åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")

def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®ä¸­æ–‡å­—ä½“
    setup_chinese_font()
    
    # åŠ è½½å’Œå‡†å¤‡æ•°æ®
    df, X, y, feature_cols = load_and_prepare_data()
    if df is None:
        return
    
    # æ‰§è¡Œç»Ÿè®¡åˆ†æ
    results_df, significant_features = perform_statistical_analysis(df, X, y, feature_cols)
    if results_df is None:
        return
    
    # æ‰§è¡Œå›å½’å»ºæ¨¡
    regression_results = perform_regression_modeling(X, y)
    
    # åˆ›å»ºå¯è§†åŒ–
    create_regression_visualizations(results_df, significant_features, regression_results)
    
    # ç”ŸæˆæŠ¥å‘Š
    generate_regression_report(results_df, significant_features, regression_results)
    
    print("\n" + "="*60)
    print("ğŸ‰ å›å½’åˆ†æå®Œæˆ!")
    print("="*60)
    print("\nç”Ÿæˆçš„æ–‡ä»¶:")
    print("  ğŸ“Š ../results/regression_analysis.png - å›å½’åˆ†æå¯è§†åŒ–")
    print("  ğŸ“ ../docs/regression_analysis_report.md - è¯¦ç»†åˆ†ææŠ¥å‘Š")
    print("\nä¸»è¦å‘ç°:")
    if len(significant_features) > 0:
        print(f"  âœ“ å‘ç° {len(significant_features)} ä¸ªæ˜¾è‘—å·®å¼‚ç‰¹å¾")
        print(f"  âœ“ æœ€å¤§æ•ˆåº”é‡: {significant_features.iloc[0]['effect_size']:.3f}")
        print(f"  âœ“ æ˜¾è‘—æ€§æ¯”ä¾‹: {len(significant_features)/len(results_df)*100:.1f}%")
    if regression_results:
        best_model = max(regression_results.keys(), key=lambda x: regression_results[x]['r2'])
        print(f"  âœ“ æœ€ä½³å›å½’æ¨¡å‹: {best_model} (RÂ² = {regression_results[best_model]['r2']:.3f})")

if __name__ == "__main__":
    main()
