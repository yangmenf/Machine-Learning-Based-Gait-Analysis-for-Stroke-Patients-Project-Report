#!/usr/bin/env python3
"""
é›†æˆåˆ†ææµæ°´çº¿
ç»Ÿä¸€çš„åˆ†ææµç¨‹ï¼šç‰¹å¾é€‰æ‹© â†’ åˆ†ç±»å»ºæ¨¡ â†’ å›å½’åˆ†æ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.linear_model import LogisticRegression, Ridge, Lasso
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from scipy import stats
from evolutionary_feature_selection import GeneticFeatureSelector
import warnings
warnings.filterwarnings('ignore')

def setup_chinese_font():
    """è®¾ç½®ä¸­æ–‡å­—ä½“"""
    import matplotlib
    font_options = [
        ['Microsoft YaHei', 'SimHei', 'Arial Unicode MS', 'DejaVu Sans'],
        ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS', 'DejaVu Sans'],
        ['Arial Unicode MS', 'Microsoft YaHei', 'SimHei', 'DejaVu Sans'],
        ['DejaVu Sans', 'Arial', 'sans-serif']
    ]
    
    for fonts in font_options:
        try:
            matplotlib.rcParams['font.sans-serif'] = fonts
            matplotlib.rcParams['axes.unicode_minus'] = False
            plt.rcParams['font.sans-serif'] = fonts
            plt.rcParams['axes.unicode_minus'] = False
            return True
        except:
            continue
    return False

def load_data():
    """æ­¥éª¤1: åŠ è½½åŸå§‹æ•°æ®"""
    print("="*70)
    print("æ­¥éª¤1: æ•°æ®åŠ è½½")
    print("="*70)
    
    try:
        df = pd.read_csv("../data/complete_gait_features.csv")
        print(f"âœ“ æˆåŠŸåŠ è½½æ•°æ®: {df.shape}")
        
        # åˆ†ç¦»ç‰¹å¾å’Œæ ‡ç­¾
        feature_cols = [col for col in df.columns if col not in ['label', 'group', 'subject_id', 'data_group', 'subject_index']]
        
        X = df[feature_cols].copy()
        y = df['label'].copy()
        
        # æ•°æ®é¢„å¤„ç†
        X = X.replace('', np.nan)
        for col in X.columns:
            X[col] = pd.to_numeric(X[col], errors='coerce')
        X = X.fillna(X.median())
        X = X.replace([np.inf, -np.inf], np.nan)
        X = X.fillna(X.median())
        
        print(f"âœ“ åŸå§‹ç‰¹å¾æ•°é‡: {X.shape[1]}")
        print(f"âœ“ æ ·æœ¬æ•°é‡: {X.shape[0]}")
        print(f"âœ“ æ ‡ç­¾åˆ†å¸ƒ: å¥åº·äºº {sum(y==0)}, ä¸­é£æ‚£è€… {sum(y==1)}")
        
        return X, y, feature_cols, df
        
    except Exception as e:
        print(f"âœ— åŠ è½½æ•°æ®å¤±è´¥: {e}")
        return None, None, None, None

def perform_feature_selection(X, y, feature_names):
    """æ­¥éª¤2: é—ä¼ ç®—æ³•ç‰¹å¾é€‰æ‹©"""
    print("\n" + "="*70)
    print("æ­¥éª¤2: é—ä¼ ç®—æ³•ç‰¹å¾é€‰æ‹©")
    print("="*70)
    
    # åˆ›å»ºç‰¹å¾é€‰æ‹©å™¨
    rf_estimator = RandomForestClassifier(n_estimators=50, random_state=42)
    
    selector = GeneticFeatureSelector(
        estimator=rf_estimator,
        n_features_to_select=120,  # é€‰æ‹©120ä¸ªç‰¹å¾
        population_size=30,
        generations=15,
        mutation_rate=0.15,
        crossover_rate=0.8,
        tournament_size=3,
        random_state=42
    )
    
    # æ‰§è¡Œç‰¹å¾é€‰æ‹©
    X_selected = selector.fit_transform(X.values, y.values)
    selected_indices = selector.selected_features_
    selected_feature_names = [feature_names[i] for i in selected_indices]
    
    print(f"âœ“ ç‰¹å¾é€‰æ‹©å®Œæˆ")
    print(f"âœ“ åŸå§‹ç‰¹å¾: {X.shape[1]} â†’ é€‰æ‹©ç‰¹å¾: {X_selected.shape[1]}")
    print(f"âœ“ ç‰¹å¾å‡å°‘æ¯”ä¾‹: {(1 - X_selected.shape[1]/X.shape[1])*100:.1f}%")
    print(f"âœ“ æœ€ä½³é€‚åº”åº¦: {selector.best_score_:.4f}")
    
    return X_selected, selected_indices, selected_feature_names, selector

def perform_classification(X_original, X_selected, y):
    """æ­¥éª¤3: åˆ†ç±»å»ºæ¨¡å¯¹æ¯”"""
    print("\n" + "="*70)
    print("æ­¥éª¤3: åˆ†ç±»å»ºæ¨¡ï¼ˆåŸå§‹ç‰¹å¾ vs é€‰æ‹©ç‰¹å¾ï¼‰")
    print("="*70)
    
    # æ•°æ®åˆ†å‰²
    X_train_orig, X_test_orig, y_train, y_test = train_test_split(
        X_original, y, test_size=0.2, random_state=42, stratify=y
    )
    
    X_train_sel, X_test_sel, _, _ = train_test_split(
        X_selected, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # æ ‡å‡†åŒ–
    scaler_orig = StandardScaler()
    scaler_sel = StandardScaler()
    
    X_train_orig_scaled = scaler_orig.fit_transform(X_train_orig)
    X_test_orig_scaled = scaler_orig.transform(X_test_orig)
    
    X_train_sel_scaled = scaler_sel.fit_transform(X_train_sel)
    X_test_sel_scaled = scaler_sel.transform(X_test_sel)
    
    # å®šä¹‰åˆ†ç±»å™¨
    classifiers = {
        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
        'SVM': SVC(random_state=42, probability=True)
    }
    
    classification_results = {}
    
    print("\nåˆ†ç±»å™¨æ€§èƒ½å¯¹æ¯”:")
    print("-" * 60)
    print(f"{'åˆ†ç±»å™¨':<15} {'åŸå§‹ç‰¹å¾':<12} {'é€‰æ‹©ç‰¹å¾':<12} {'æ€§èƒ½å˜åŒ–':<10}")
    print("-" * 60)
    
    for name, clf in classifiers.items():
        # åŸå§‹ç‰¹å¾
        clf_orig = clf.__class__(**clf.get_params())
        clf_orig.fit(X_train_orig_scaled, y_train)
        y_pred_orig = clf_orig.predict(X_test_orig_scaled)
        acc_orig = accuracy_score(y_test, y_pred_orig)
        
        # é€‰æ‹©ç‰¹å¾
        clf_sel = clf.__class__(**clf.get_params())
        clf_sel.fit(X_train_sel_scaled, y_train)
        y_pred_sel = clf_sel.predict(X_test_sel_scaled)
        acc_sel = accuracy_score(y_test, y_pred_sel)
        
        improvement = acc_sel - acc_orig
        
        classification_results[name] = {
            'original_accuracy': acc_orig,
            'selected_accuracy': acc_sel,
            'improvement': improvement
        }
        
        print(f"{name:<15} {acc_orig:<12.4f} {acc_sel:<12.4f} {improvement*100:<+10.2f}%")
    
    return classification_results, y_test

def perform_regression_analysis(X_original, X_selected, y, selected_feature_names):
    """æ­¥éª¤4: å›å½’åˆ†æï¼ˆåŸºäºé€‰æ‹©çš„ç‰¹å¾ï¼‰"""
    print("\n" + "="*70)
    print("æ­¥éª¤4: å›å½’åˆ†æï¼ˆä½¿ç”¨é€‰æ‹©çš„ç‰¹å¾ï¼‰")
    print("="*70)
    
    # ä½¿ç”¨é€‰æ‹©çš„ç‰¹å¾è¿›è¡Œç»Ÿè®¡åˆ†æ
    print("è¿›è¡Œç»Ÿè®¡æ˜¾è‘—æ€§åˆ†æ...")
    
    # åˆ†ç»„æ•°æ®
    healthy_indices = y == 0
    stroke_indices = y == 1
    
    statistical_results = []
    
    for i, feature_name in enumerate(selected_feature_names):
        try:
            healthy_values = X_selected[healthy_indices, i]
            stroke_values = X_selected[stroke_indices, i]
            
            # ç‹¬ç«‹æ ·æœ¬tæ£€éªŒ
            t_stat, p_value = stats.ttest_ind(healthy_values, stroke_values)
            
            # è®¡ç®—æ•ˆåº”é‡ (Cohen's d)
            pooled_std = np.sqrt(((len(healthy_values) - 1) * np.var(healthy_values, ddof=1) + 
                                (len(stroke_values) - 1) * np.var(stroke_values, ddof=1)) / 
                               (len(healthy_values) + len(stroke_values) - 2))
            
            if pooled_std > 0:
                cohens_d = (np.mean(healthy_values) - np.mean(stroke_values)) / pooled_std
            else:
                cohens_d = 0
            
            statistical_results.append({
                'feature': feature_name,
                'healthy_mean': np.mean(healthy_values),
                'stroke_mean': np.mean(stroke_values),
                'mean_difference': np.mean(healthy_values) - np.mean(stroke_values),
                't_statistic': t_stat,
                'p_value': p_value,
                'cohens_d': cohens_d,
                'effect_size': abs(cohens_d)
            })
        except Exception as e:
            continue
    
    # è½¬æ¢ä¸ºDataFrameå¹¶æ’åº
    results_df = pd.DataFrame(statistical_results)
    results_df = results_df.sort_values('effect_size', ascending=False)
    
    # æ˜¾è‘—æ€§ç­›é€‰
    significant_features = results_df[results_df['p_value'] < 0.05]
    
    print(f"âœ“ åˆ†æäº† {len(results_df)} ä¸ªé€‰æ‹©çš„ç‰¹å¾")
    print(f"âœ“ å‘ç° {len(significant_features)} ä¸ªæ˜¾è‘—å·®å¼‚ç‰¹å¾")
    print(f"âœ“ æ˜¾è‘—æ€§æ¯”ä¾‹: {len(significant_features)/len(results_df)*100:.1f}%")
    
    # æ˜¾ç¤ºå‰10ä¸ªæœ€æ˜¾è‘—çš„å·®å¼‚
    print(f"\nå‰10ä¸ªæœ€æ˜¾è‘—çš„å·®å¼‚ç‰¹å¾:")
    print("-" * 80)
    for i, row in significant_features.head(10).iterrows():
        effect_level = "å¤§" if abs(row['cohens_d']) > 0.8 else "ä¸­" if abs(row['cohens_d']) > 0.5 else "å°"
        print(f"{row['feature'][:30]:<30} | æ•ˆåº”é‡: {row['cohens_d']:.3f} ({effect_level}) | på€¼: {row['p_value']:.6f}")
    
    return results_df, significant_features

def create_integrated_visualization(selector, classification_results, regression_results, X_original, X_selected):
    """æ­¥éª¤5: åˆ›å»ºé›†æˆå¯è§†åŒ–"""
    print("\n" + "="*70)
    print("æ­¥éª¤5: ç”Ÿæˆé›†æˆåˆ†æå¯è§†åŒ–")
    print("="*70)
    
    setup_chinese_font()
    
    # ç”¨æˆ·åå¥½çš„é¢œè‰²æ–¹æ¡ˆ
    COLORS = ['#98CFE6', '#ADE7A8', '#F39F4E', '#EEB7D3', '#DBDAD3', '#FFDF97']
    
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('é›†æˆåˆ†ææµæ°´çº¿ç»“æœ', fontsize=16, fontweight='bold')
    
    # 1. ç‰¹å¾é€‰æ‹©è¿›åŒ–è¿‡ç¨‹
    ax1 = axes[0, 0]
    generations = range(1, len(selector.best_fitness_history) + 1)
    ax1.plot(generations, selector.best_fitness_history, 'o-', color=COLORS[0], linewidth=2, markersize=4)
    ax1.set_xlabel('è¿›åŒ–ä»£æ•°')
    ax1.set_ylabel('æœ€ä½³é€‚åº”åº¦')
    ax1.set_title('ç‰¹å¾é€‰æ‹©è¿›åŒ–è¿‡ç¨‹')
    ax1.grid(True, alpha=0.3)
    
    # 2. ç‰¹å¾æ•°é‡å¯¹æ¯”
    ax2 = axes[0, 1]
    feature_counts = [X_original.shape[1], X_selected.shape[1]]
    labels = ['åŸå§‹ç‰¹å¾', 'é€‰æ‹©ç‰¹å¾']
    colors = [COLORS[1], COLORS[2]]
    
    bars = ax2.bar(labels, feature_counts, color=colors, alpha=0.8)
    ax2.set_ylabel('ç‰¹å¾æ•°é‡')
    ax2.set_title('ç‰¹å¾æ•°é‡å¯¹æ¯”')
    
    for bar in bars:
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height + 5,
                f'{int(height)}', ha='center', va='bottom', fontsize=10, fontweight='bold')
    
    # 3. åˆ†ç±»æ€§èƒ½å¯¹æ¯”
    ax3 = axes[0, 2]
    classifiers = list(classification_results.keys())
    orig_accs = [classification_results[clf]['original_accuracy'] for clf in classifiers]
    sel_accs = [classification_results[clf]['selected_accuracy'] for clf in classifiers]
    
    x = np.arange(len(classifiers))
    width = 0.35
    
    bars1 = ax3.bar(x - width/2, orig_accs, width, label='åŸå§‹ç‰¹å¾', color=COLORS[3], alpha=0.8)
    bars2 = ax3.bar(x + width/2, sel_accs, width, label='é€‰æ‹©ç‰¹å¾', color=COLORS[4], alpha=0.8)
    
    ax3.set_xlabel('åˆ†ç±»å™¨')
    ax3.set_ylabel('å‡†ç¡®ç‡')
    ax3.set_title('åˆ†ç±»æ€§èƒ½å¯¹æ¯”')
    ax3.set_xticks(x)
    ax3.set_xticklabels([clf.replace(' ', '\n') for clf in classifiers])
    ax3.legend()
    ax3.set_ylim(0.9, 1.0)
    
    # 4. å›å½’åˆ†ææ•ˆåº”é‡åˆ†å¸ƒ
    ax4 = axes[1, 0]
    if len(regression_results) > 0:
        effect_sizes = regression_results['effect_size'].values
        ax4.hist(effect_sizes, bins=15, color=COLORS[5], alpha=0.7, edgecolor='black')
        ax4.axvline(x=0.2, color='green', linestyle='--', label='å°æ•ˆåº” (0.2)')
        ax4.axvline(x=0.5, color='orange', linestyle='--', label='ä¸­æ•ˆåº” (0.5)')
        ax4.axvline(x=0.8, color='red', linestyle='--', label='å¤§æ•ˆåº” (0.8)')
        ax4.set_xlabel('æ•ˆåº”é‡ (Cohen\'s d)')
        ax4.set_ylabel('ç‰¹å¾æ•°é‡')
        ax4.set_title('é€‰æ‹©ç‰¹å¾çš„æ•ˆåº”é‡åˆ†å¸ƒ')
        ax4.legend(fontsize=8)
    
    # 5. æ˜¾è‘—æ€§ç‰¹å¾æ¯”ä¾‹
    ax5 = axes[1, 1]
    if len(regression_results) > 0:
        significant_count = len(regression_results[regression_results['p_value'] < 0.05])
        non_significant_count = len(regression_results) - significant_count
        
        sizes = [significant_count, non_significant_count]
        labels = [f'æ˜¾è‘—\n({significant_count})', f'éæ˜¾è‘—\n({non_significant_count})']
        colors = [COLORS[0], COLORS[1]]
        
        wedges, texts, autotexts = ax5.pie(sizes, labels=labels, autopct='%1.1f%%', 
                                          colors=colors, startangle=90)
        ax5.set_title('é€‰æ‹©ç‰¹å¾æ˜¾è‘—æ€§åˆ†å¸ƒ')
    
    # 6. æµæ°´çº¿æ€»ç»“
    ax6 = axes[1, 2]
    ax6.axis('off')
    
    # æ·»åŠ æ–‡æœ¬æ€»ç»“
    summary_text = f"""
é›†æˆåˆ†ææµæ°´çº¿æ€»ç»“

æ­¥éª¤1: æ•°æ®åŠ è½½
â€¢ æ ·æœ¬æ•°é‡: {X_original.shape[0]}
â€¢ åŸå§‹ç‰¹å¾: {X_original.shape[1]}

æ­¥éª¤2: ç‰¹å¾é€‰æ‹©
â€¢ é€‰æ‹©ç‰¹å¾: {X_selected.shape[1]}
â€¢ é™ç»´æ¯”ä¾‹: {(1-X_selected.shape[1]/X_original.shape[1])*100:.1f}%

æ­¥éª¤3: åˆ†ç±»å»ºæ¨¡
â€¢ æœ€ä½³å‡†ç¡®ç‡: {max([r['selected_accuracy'] for r in classification_results.values()]):.4f}

æ­¥éª¤4: å›å½’åˆ†æ
â€¢ æ˜¾è‘—ç‰¹å¾: {len(regression_results[regression_results['p_value'] < 0.05]) if len(regression_results) > 0 else 0}
â€¢ æ˜¾è‘—æ¯”ä¾‹: {len(regression_results[regression_results['p_value'] < 0.05])/len(regression_results)*100:.1f}%
    """
    
    ax6.text(0.1, 0.9, summary_text, transform=ax6.transAxes, fontsize=10,
             verticalalignment='top', bbox=dict(boxstyle='round', facecolor=COLORS[2], alpha=0.3))
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    output_file = "../results/integrated_analysis_pipeline.png"
    plt.savefig(output_file, dpi=300, bbox_inches='tight', facecolor='white')
    print(f"âœ“ é›†æˆåˆ†æå¯è§†åŒ–å·²ä¿å­˜: {output_file}")
    
    plt.close()

def generate_pipeline_report(selector, classification_results, regression_results, selected_feature_names, X_original, X_selected):
    """ç”Ÿæˆé›†æˆåˆ†ææŠ¥å‘Š"""
    print("ç”Ÿæˆé›†æˆåˆ†ææŠ¥å‘Š...")
    
    report_file = "../docs/integrated_analysis_pipeline_report.md"
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("# é›†æˆåˆ†ææµæ°´çº¿æŠ¥å‘Š\n\n")
        f.write("## åˆ†ææµç¨‹\n\n")
        f.write("æœ¬æŠ¥å‘Šå±•ç¤ºäº†å®Œæ•´çš„é›†æˆåˆ†ææµæ°´çº¿ï¼š**ç‰¹å¾é€‰æ‹© â†’ åˆ†ç±»å»ºæ¨¡ â†’ å›å½’åˆ†æ**\n\n")
        
        f.write("### æ­¥éª¤1: æ•°æ®åŠ è½½\n")
        f.write(f"- **æ ·æœ¬æ•°é‡**: {X_original.shape[0]}\n")
        f.write(f"- **åŸå§‹ç‰¹å¾æ•°**: {X_original.shape[1]}\n\n")
        
        f.write("### æ­¥éª¤2: é—ä¼ ç®—æ³•ç‰¹å¾é€‰æ‹©\n")
        f.write(f"- **é€‰æ‹©ç‰¹å¾æ•°**: {X_selected.shape[1]}\n")
        f.write(f"- **é™ç»´æ¯”ä¾‹**: {(1-X_selected.shape[1]/X_original.shape[1])*100:.1f}%\n")
        f.write(f"- **æœ€ä½³é€‚åº”åº¦**: {selector.best_score_:.4f}\n\n")
        
        f.write("### æ­¥éª¤3: åˆ†ç±»å»ºæ¨¡å¯¹æ¯”\n")
        f.write("| åˆ†ç±»å™¨ | åŸå§‹ç‰¹å¾å‡†ç¡®ç‡ | é€‰æ‹©ç‰¹å¾å‡†ç¡®ç‡ | æ€§èƒ½å˜åŒ– |\n")
        f.write("|--------|----------------|----------------|----------|\n")
        
        for clf_name, result in classification_results.items():
            f.write(f"| {clf_name} | {result['original_accuracy']:.4f} | {result['selected_accuracy']:.4f} | {result['improvement']*100:+.2f}% |\n")
        
        f.write("\n### æ­¥éª¤4: å›å½’åˆ†æç»“æœ\n")
        if len(regression_results) > 0:
            significant_count = len(regression_results[regression_results['p_value'] < 0.05])
            f.write(f"- **åˆ†æç‰¹å¾æ•°**: {len(regression_results)}\n")
            f.write(f"- **æ˜¾è‘—å·®å¼‚ç‰¹å¾**: {significant_count}\n")
            f.write(f"- **æ˜¾è‘—æ€§æ¯”ä¾‹**: {significant_count/len(regression_results)*100:.1f}%\n\n")
            
            f.write("#### å‰10ä¸ªæœ€æ˜¾è‘—å·®å¼‚ç‰¹å¾\n")
            significant_features = regression_results[regression_results['p_value'] < 0.05].head(10)
            for i, row in significant_features.iterrows():
                f.write(f"{i+1}. **{row['feature']}**: æ•ˆåº”é‡ {row['cohens_d']:.3f}, på€¼ {row['p_value']:.6f}\n")
        
        f.write("\n## ä¸»è¦ä¼˜åŠ¿\n\n")
        f.write("1. **ç»Ÿä¸€æµç¨‹**: ç‰¹å¾é€‰æ‹©â†’åˆ†ç±»â†’å›å½’çš„å®Œæ•´åˆ†æé“¾\n")
        f.write("2. **æ™ºèƒ½ä¼˜åŒ–**: é—ä¼ ç®—æ³•è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç‰¹å¾å­é›†\n")
        f.write("3. **æ€§èƒ½ä¿æŒ**: å¤§å¹…é™ç»´çš„åŒæ—¶ä¿æŒåˆ†ç±»æ€§èƒ½\n")
        f.write("4. **æ·±åº¦åˆ†æ**: åŸºäºä¼˜åŒ–ç‰¹å¾è¿›è¡Œç»Ÿè®¡åˆ†æ\n\n")
        
        f.write("---\n\n")
        f.write("**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: 2025å¹´7æœˆ4æ—¥\n")
        f.write("**åˆ†ææ–¹æ³•**: é›†æˆåˆ†ææµæ°´çº¿\n")
    
    print(f"âœ“ é›†æˆåˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_file}")

def main():
    """ä¸»å‡½æ•° - æ‰§è¡Œå®Œæ•´çš„é›†æˆåˆ†ææµæ°´çº¿"""
    print("ğŸš€ å¯åŠ¨é›†æˆåˆ†ææµæ°´çº¿")
    print("æµç¨‹: æ•°æ®åŠ è½½ â†’ ç‰¹å¾é€‰æ‹© â†’ åˆ†ç±»å»ºæ¨¡ â†’ å›å½’åˆ†æ â†’ ç»“æœå¯è§†åŒ–")
    
    # æ­¥éª¤1: åŠ è½½æ•°æ®
    X, y, feature_names, df = load_data()
    if X is None:
        return
    
    # æ­¥éª¤2: ç‰¹å¾é€‰æ‹©
    X_selected, selected_indices, selected_feature_names, selector = perform_feature_selection(X, y, feature_names)
    
    # æ­¥éª¤3: åˆ†ç±»å»ºæ¨¡
    classification_results, y_test = perform_classification(X.values, X_selected, y.values)
    
    # æ­¥éª¤4: å›å½’åˆ†æ
    regression_results, significant_features = perform_regression_analysis(X.values, X_selected, y.values, selected_feature_names)
    
    # æ­¥éª¤5: å¯è§†åŒ–
    create_integrated_visualization(selector, classification_results, regression_results, X.values, X_selected)
    
    # ç”ŸæˆæŠ¥å‘Š
    generate_pipeline_report(selector, classification_results, regression_results, selected_feature_names, X.values, X_selected)
    
    # ä¿å­˜é€‰æ‹©çš„ç‰¹å¾
    selected_features_df = pd.DataFrame({
        'feature_index': selected_indices,
        'feature_name': selected_feature_names
    })
    selected_features_df.to_csv("../results/pipeline_selected_features.csv", index=False)
    
    print("\n" + "="*70)
    print("ğŸ‰ é›†æˆåˆ†ææµæ°´çº¿å®Œæˆ!")
    print("="*70)
    
    best_classifier = max(classification_results.keys(), key=lambda x: classification_results[x]['selected_accuracy'])
    best_accuracy = classification_results[best_classifier]['selected_accuracy']
    significant_count = len(regression_results[regression_results['p_value'] < 0.05]) if len(regression_results) > 0 else 0
    
    print(f"\nğŸ“Š æµæ°´çº¿æ€»ç»“:")
    print(f"  âœ“ ç‰¹å¾ä¼˜åŒ–: {X.shape[1]} â†’ {X_selected.shape[1]} ({(1-X_selected.shape[1]/X.shape[1])*100:.1f}% é™ç»´)")
    print(f"  âœ“ æœ€ä½³åˆ†ç±»å™¨: {best_classifier}")
    print(f"  âœ“ æœ€é«˜å‡†ç¡®ç‡: {best_accuracy:.4f}")
    print(f"  âœ“ æ˜¾è‘—å·®å¼‚ç‰¹å¾: {significant_count}")
    print(f"  âœ“ é—ä¼ ç®—æ³•é€‚åº”åº¦: {selector.best_score_:.4f}")
    
    print(f"\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"  ğŸ“Š ../results/integrated_analysis_pipeline.png - é›†æˆåˆ†æå¯è§†åŒ–")
    print(f"  ğŸ“‹ ../docs/integrated_analysis_pipeline_report.md - é›†æˆåˆ†ææŠ¥å‘Š")
    print(f"  ğŸ“„ ../results/pipeline_selected_features.csv - æµæ°´çº¿é€‰æ‹©çš„ç‰¹å¾")

if __name__ == "__main__":
    main()
